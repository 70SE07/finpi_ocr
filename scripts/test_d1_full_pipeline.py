"""
–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç D1 Pipeline –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —á–µ–∫–µ.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª:
1. ‚úÖ Preprocessing (6 stages) —Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º–∏
2. ‚úÖ OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Google Vision
3. ‚úÖ Feedback Loop —Å –≤—Å–µ–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
4. ‚úÖ RawOCRResult –∫–æ–Ω—Ç—Ä–∞–∫—Ç –≤–∞–ª–∏–¥–µ–Ω
5. ‚úÖ Words —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
"""

import json
from pathlib import Path
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.extraction.application.factory import ExtractionComponentFactory
from contracts.d1_extraction_dto import RawOCRResult


def test_full_pipeline(image_path: Path, strategy_config: dict = None) -> dict:
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π D1 pipeline —Å OCR.
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        strategy_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ retry (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    logger.info(f"\n{'='*70}")
    logger.info("–ü–û–õ–ù–´–ô –¢–ï–°–¢ D1 PIPELINE –° OCR")
    logger.info(f"{'='*70}")
    logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path.name}")
    logger.info(f"–†–∞–∑–º–µ—Ä: {image_path.stat().st_size / 1024:.1f} KB")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π pipeline
        extraction_pipeline = ExtractionComponentFactory.create_default_extraction_pipeline()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π pipeline (preprocessing + OCR)
        logger.info("\n–ó–∞–ø—É—Å–∫ ExtractionPipeline...")
        raw_ocr_result = extraction_pipeline.process_image(image_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º RawOCRResult –∫–æ–Ω—Ç—Ä–∞–∫—Ç
        logger.success(f"\n‚úÖ RawOCRResult –ø–æ–ª—É—á–µ–Ω")
        logger.info(f"  Full text length: {len(raw_ocr_result.full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"  Words count: {len(raw_ocr_result.words)} —Å–ª–æ–≤")
        logger.info(f"  Source file: {raw_ocr_result.metadata.source_file}")
        logger.info(f"  Image size: {raw_ocr_result.metadata.image_width}x{raw_ocr_result.metadata.image_height}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è full_text
        if not raw_ocr_result.full_text or not raw_ocr_result.full_text.strip():
            logger.error("‚ùå Full text –ø—É—Å—Ç!")
            return {
                'success': False,
                'error': 'empty_full_text'
            }
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è words[]
        if not raw_ocr_result.words:
            logger.error("‚ùå Words[] –ø—É—Å—Ç!")
            return {
                'success': False,
                'error': 'empty_words'
            }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Å–ª–æ–≤–∞ –≤–∞–ª–∏–¥–Ω—ã
        word_errors = []
        for i, word in enumerate(raw_ocr_result.words, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º bounding box
            bbox = word.bounding_box
            if bbox.x < 0 or bbox.y < 0:
                word_errors.append(f"Word {i}: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ({bbox.x}, {bbox.y})")
            if bbox.width <= 0 or bbox.height <= 0:
                word_errors.append(f"Word {i}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã ({bbox.width}x{bbox.height})")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º confidence
            if not (0.0 <= word.confidence <= 1.0):
                word_errors.append(f"Word {i}: confidence {word.confidence} –≤–Ω–µ [0, 1]")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º text
            if not word.text or not word.text.strip():
                word_errors.append(f"Word {i}: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
        
        if word_errors:
            logger.error(f"‚ùå –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ —Å–ª–æ–≤–∞—Ö:")
            for error in word_errors[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                logger.error(f"  {error}")
            return {
                'success': False,
                'error': 'invalid_words',
                'details': word_errors
            }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        width = raw_ocr_result.metadata.image_width
        height = raw_ocr_result.metadata.image_height
        
        coord_errors = []
        for i, word in enumerate(raw_ocr_result.words, 1):
            bbox = word.bounding_box
            if bbox.x + bbox.width > width:
                coord_errors.append(f"Word {i}: XË∂ÖÂá∫ ({bbox.x + bbox.width} > {width})")
            if bbox.y + bbox.height > height:
                coord_errors.append(f"Word {i}: YË∂ÖÂá∫ ({bbox.y + bbox.height} > {height})")
        
        if coord_errors:
            logger.warning(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–ª–æ–≤–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ (–ø–µ—Ä–≤—ã–µ 5):")
            for error in coord_errors[:5]:
                logger.warning(f"  {error}")
        else:
            logger.success(f"‚úÖ –í—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö {width}x{height}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º preprocessing metadata
        preprocessing = raw_ocr_result.metadata.preprocessing_applied
        logger.info(f"\n–ü—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–π preprocessing:")
        logger.info(f"  –§–∏–ª—å—Ç—Ä—ã: {preprocessing}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º retry_info –µ—Å–ª–∏ –µ—Å—Ç—å
        if raw_ocr_result.metadata.retry_info:
            retry = raw_ocr_result.metadata.retry_info
            logger.info(f"\nFeedback Loop info:")
            logger.info(f"  –ü–æ–ø—ã—Ç–æ–∫: {retry.get('attempts', 1)}")
            logger.info(f"  –ë—ã–ª retry: {retry.get('was_retried', False)}")
            logger.info(f"  –°—Ç—Ä–∞—Ç–µ–≥–∏–∏: {retry.get('strategies_used', [])}")
            logger.info(f"  Final avg confidence: {retry.get('final_avg_confidence', 0):.3f}")
            logger.info(f"  Final min confidence: {retry.get('final_min_confidence', 0):.3f}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–µ–¥–Ω–∏–π confidence
        avg_confidence = sum(w.confidence for w in raw_ocr_result.words) / len(raw_ocr_result.words)
        min_confidence = min(w.confidence for w in raw_ocr_result.words)
        max_confidence = max(w.confidence for w in raw_ocr_result.words)
        
        logger.success(f"\n‚úÖ OCR Quality Metrics:")
        logger.info(f"  Average confidence: {avg_confidence:.3f} [0-1]")
        logger.info(f"  Min confidence:     {min_confidence:.3f}")
        logger.info(f"  Max confidence:     {max_confidence:.3f}")
        logger.info(f"  Low confidence words: {sum(1 for w in raw_ocr_result.words if w.confidence < 0.85)} / {len(raw_ocr_result.words)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ confidence –≤–∞–ª–∏–¥–µ–Ω
        if not (0.0 <= avg_confidence <= 1.0):
            logger.error(f"‚ùå Average confidence {avg_confidence} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0, 1]")
            return {
                'success': False,
                'error': 'invalid_confidence'
            }
        
        result = {
            'success': True,
            'image': image_path.name,
            'full_text_length': len(raw_ocr_result.full_text),
            'words_count': len(raw_ocr_result.words),
            'avg_confidence': round(avg_confidence, 3),
            'min_confidence': round(min_confidence, 3),
            'max_confidence': round(max_confidence, 3),
            'image_size': f"{width}x{height}",
            'preprocessing': preprocessing,
            'sample_words': [
                {
                    'text': word.text,
                    'confidence': round(word.confidence, 3),
                    'bbox': f"{word.bounding_box.x},{word.bounding_box.y},{word.bounding_box.width}x{word.bounding_box.height}"
                }
                for word in raw_ocr_result.words[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Å–ª–æ–≤
            ]
        }
        
        if raw_ocr_result.metadata.retry_info:
            result['retry_info'] = raw_ocr_result.metadata.retry_info
        
        logger.success(f"\n‚úÖ –ü–û–õ–ù–´–ô –¢–ï–°–¢ D1 PASSED!")
        return result
        
    except Exception as e:
        logger.error(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–µ: {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e),
            'image': image_path.name
        }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    logger.info("="*70)
    logger.info("–ü–û–õ–ù–´–ô –¢–ï–°–¢ D1 PIPELINE –° GOOGLE VISION OCR")
    logger.info("="*70)
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —á–µ–∫
    input_dir = Path(__file__).parent.parent / "data" / "input"
    image_files = list(input_dir.glob("*.jpeg")) + list(input_dir.glob("*.jpg"))
    
    if not image_files:
        logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ {input_dir}")
        return
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —á–µ–∫
    test_image = image_files[0]
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π pipeline
    result = test_full_pipeline(test_image)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_file = Path(__file__).parent / "d1_full_pipeline_test_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'test_image': str(test_image),
            'image_size_kb': test_image.stat().st_size / 1024,
            'result': result
        }, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
    logger.info(f"\n{'='*70}")
    if result['success']:
        logger.success("üéâ D1 PIPELINE –ü–û–õ–ù–û–°–¢–¨–Æ –†–ê–ë–û–¢–ê–ï–¢!")
        logger.success("‚úÖ RawOCRResult –∫–æ–Ω—Ç—Ä–∞–∫—Ç –≤–∞–ª–∏–¥–µ–Ω")
        logger.success("‚úÖ OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        logger.success("‚úÖ Words[] —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")
        logger.success("‚úÖ Confidence –≤–∞–ª–∏–¥–µ–Ω")
        logger.success("‚úÖ Full text –ø–æ–ª—É—á–µ–Ω")
        
        # –î–µ—Ç–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        logger.info(f"\n–î–µ—Ç–∞–ª–∏:")
        logger.info(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['image']}")
        logger.info(f"  –†–∞–∑–º–µ—Ä: {result['image_size']}")
        logger.info(f"  –°–ª–æ–≤–∞: {result['words_count']}")
        logger.info(f"  Full text: {result['full_text_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"  Avg confidence: {result['avg_confidence']}")
        logger.info(f"  –§–∏–ª—å—Ç—Ä—ã: {result['preprocessing']}")
        
        if 'retry_info' in result:
            logger.info(f"  –ë—ã–ª–∏ retry: {result['retry_info'].get('was_retried', False)}")
    else:
        logger.error("‚ùå –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –í D1 PIPELINE")
        logger.error(f"–û—à–∏–±–∫–∞: {result.get('error', 'unknown')}")
    logger.info(f"{'='*70}\n")


if __name__ == "__main__":
    main()
