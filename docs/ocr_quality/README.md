# Методология сбора OCR-артефактов

Документ описывает систематический подход к сбору, классификации и документированию OCR-артефактов для реализации Stage 1: OCR Cleanup.

---

## Цель

Создать систематизированную базу знаний об OCR-артефактах для построения универсального модуля очистки.

**Результат:** 10-100 задокументированных паттернов артефактов по каждой локали.

---

## Структура документации

```
docs/ocr_quality/
├── README.md                    # Методология (этот файл)
├── ARTIFACT_TYPES.md           # Классификация типов артефактов
├── MATRIX.md                   # Агрегированная матрица артефактов
├── MATRIX.json                 # Machine-readable версия
└── by_locale/
    ├── de_DE/
    │   ├── _index.json         # Статистика локали
    │   └── artifacts.json      # Все артефакты локали
    ├── pl_PL/
    │   ├── _index.json
    │   └── artifacts.json
    └── ...
```

---

## Алгоритм анализа одного чека

### Входные данные

Для каждого чека необходимы:

1. **`data/output/{receipt_id}/raw_ocr.json`** - результат OCR (D1 output)
   - `full_text` - полный текст чека
   - `words` - список слов с координатами и confidence

2. **`docs/ground_truth/{id}_{locale}_{store}_{file}.json`** - эталон (Ground Truth)
   - `items` - список товаров с правильными названиями
   - `metadata` - корректные метаданные (дата, сумма и т.д.)

### Пошаговый алгоритм

```
Шаг 1: Загрузка данных
├─ Открыть raw_ocr.json
├─ Открыть ground_truth.json
└─ Записать metadata: locale, store, source_file

Шаг 2: Сравнение названий товаров
├─ Для каждого item в ground_truth.items:
│  ├─ Найти соответствующую строку в raw_ocr.full_text
│  ├─ Если найдено точно → пропустить
│  ├─ Если найдено с отличиями → записать артефакт
│  └─ Если не найдено → записать WORD_SPLIT или CHAR_MISS
└─ Сравнить по нечёткому совпадению (Levenshtein distance)

Шаг 3: Анализ цен
├─ Для каждой цены в ground_truth:
│  ├─ Проверить формат (запятая vs точка)
│  ├─ Проверить склейку с названием
│  └─ Записать артефакты NUM_FMT или WORD_MERGE
└─ Проверить разделитель на соответствие локали

Шаг 4: Поиск мусора
├─ Сканировать raw_ocr.full_text на:
│  ├─ Повторяющиеся спецсимволы: ***, ---, |||
│  ├─ Изолированные символы: |, \, ~, ^
│  └─ Нечитаемые последовательности
└─ Записать артефакты GARBAGE

Шаг 5: Проверка диакритики (для локалей с диакритикой)
├─ Для pl_PL: ą, ć, ę, ł, ń, ó, ś, ź, ż
├─ Для cs_CZ: á, č, ď, é, ě, í, ň, ó, ř, š, ť, ú, ů, ý, ž
├─ Для de_DE: ä, ö, ü, ß
└─ Для es_ES: á, é, í, ó, ú, ü, ñ, ç
   └─ Записать артефакты DIAC_LOSS

Шаг 6: Проверка смешения алфавитов (для кириллицы)
├─ Для uk_UA, bg_BG, ru_RU:
│  ├─ Проверить латинские символы в кириллических словах
│  │  a/а, e/е, o/о, p/р, c/с, x/х, i/і
│  └─ Записать артефакты SCRIPT_MIX
└─ Проверить кириллические символы в латинских словах

Шаг 7: Классификация и сохранение
├─ Присвоить каждому артефакту:
│  ├─ type (из ARTIFACT_TYPES.md)
│  ├─ frequency: rare/occasional/frequent
│  └─ fix_rule (предложение по исправлению)
├─ Вычислить статистику чека
└─ Сохранить в docs/ocr_quality/by_locale/{locale}/
```

---

## Чек-лист для ручного анализа

Использовать для каждого анализируемого чека:

```markdown
## Чек: [receipt_id]
Локаль: [xx_XX]
Магазин: [store]
Файл: [source_file]

### 1. Названия товаров
- [ ] Все названия найдены в OCR?
- [ ] Есть замены символов? (O/0, l/1, etc.)
- [ ] Есть разрывы слов?
- [ ] Есть склейки слов?

### 2. Цены
- [ ] Формат правильный? (запятая/точка)
- [ ] Цены отделены от названий?
- [ ] Числа распознаны корректно?

### 3. Специальные символы
- [ ] Диакритика сохранена?
- [ ] Нет смешения алфавитов?
- [ ] Нет мусорных символов?

### 4. Найденные артефакты
| # | Тип | OCR | Ожидалось | Правило |
|---|-----|-----|-----------|---------|
| 1 |     |     |           |         |
| 2 |     |     |           |         |
```

---

## Агрегация и анализ

### После анализа N чеков локали

1. Собрать все артефакты в `by_locale/{locale}/artifacts.json`
2. Вычислить частотность каждого типа артефактов
3. Выделить TOP-10 самых частых артефактов
4. Сформулировать правила очистки (fix_rules)

### Формат _index.json (статистика локали)

```json
{
  "locale": "de_DE",
  "receipts_analyzed": 36,
  "stores_covered": ["lidl", "aldi", "hit", "edeka", "penny", "netto", "dm", "shell"],
  "total_words": 12584,
  "total_artifacts": 127,
  "artifact_rate": 0.010,
  "by_type": {
    "CHAR_SUB": { "count": 45, "percentage": 35.4 },
    "WORD_SPLIT": { "count": 23, "percentage": 18.1 },
    "GARBAGE": { "count": 19, "percentage": 15.0 }
  },
  "top_patterns": [
    {
      "pattern": "0 → O at word start",
      "type": "CHAR_SUB",
      "occurrences": 12,
      "examples": ["0livenöle", "0bst"]
    }
  ],
  "last_updated": "2025-01-03"
}
```

### Формат artifacts.json (все артефакты локали)

```json
[
  {
    "id": "de_DE_001",
    "receipt_id": "IMG_1292",
    "type": "CHAR_SUB",
    "ocr_text": "0livenöle",
    "expected_text": "Olivenöl",
    "position": "word",
    "context": "0livenöle natur",
    "frequency": "rare",
    "confidence": 0.85,
    "fix_rule": {
      "pattern": "^0(?=[a-zäöü])",
      "replacement": "O",
      "context": "at word start before lowercase"
    }
  }
]
```

---

## Критерии завершения

### Минимум для одной локали

- ✅ 10+ чеков проанализировано
- ✅ 10+ уникальных паттернов найдено
- ✅ TOP-5 паттернов задокументировано с fix_rules

### Готовность к реализации s1_ocr_cleanup

- ✅ 3+ локали проанализировано
- ✅ Общая матрица артефактов создана (MATRIX.md)
- ✅ Универсальные правила выделены (работают для всех локалей)
- ✅ Locale-specific правила задокументированы

---

## Приоритет локалей для анализа

| Приоритет | Локаль | Чеков | Причина |
|-----------|--------|-------|---------|
| 1 | de_DE | 36 | Больше всего данных |
| 2 | pl_PL | 8 | Диакритика, второй по размеру |
| 3 | th_TH | 7 | Нелатинский скрипт |
| 4 | uk_UA | 1 | Кириллица, смешение алфавитов |
| 5 | bg_BG | 1 | Кириллица |

---

## Инструменты

### Скрипт для автоматизации сравнения

`scripts/analyze_ocr_artifacts.py`:

```python
# Функционал:
- Вход: receipt_id
- Выход: предварительный список артефактов в JSON
- Человек валидирует и дополняет вручную
```

### Визуализация

Для сложных случаев:

1. Открыть исходное изображение чека
2. Сравнить визуально OCR текст с реальным текстом
3. Понять причину артефакта:
   - Качество фото
   - Шрифт чека
   - Форматирование (линии, рамки)
   - Разрешение

---

## Следующие шаги

После создания структуры:

1. ✅ Создать ARTIFACT_TYPES.md
2. Анализировать чеки по алгоритму
3. Агрегировать данные в MATRIX.md
4. Сформулировать правила для s1_ocr_cleanup

---

## Связанные документы

- [ARTIFACT_TYPES.md](ARTIFACT_TYPES.md) - классификатор артефактов
- [MATRIX.md](MATRIX.md) - агрегированная матрица
- [by_locale/](by_locale/) - детальные артефакты по локалям
